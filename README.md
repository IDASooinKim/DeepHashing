<div align="center">

# Enhancing deephashing with graph filters and autoencoder-based embeddings

![poster](./images/arch.png)
<div align="left">

## Description

*This is a PyTorch implementation of a deep hashing algorithm integrated with a __mini-batch-based graph construction__ module. The provided experiments and dataset use [Stanford Cars](https://ai.stanford.edu/~jkrause/cars/car_dataset.html).
This code implements a basic image retrieval pipeline using the proposed self-supervised deep hashing model, HAGCN. The script takes an embedded dataset of images generated by the backbone model as input. After tuning the model's hyperparameters, the training process allows the model to generate binary hash codes. The code is modular, with separate functions for data loading, preprocessing, feature extraction, model training, and evaluation. In the final part of the script, the model is tested on a test dataset to demonstrate its retrieval capabilities.*

## Dataset Information

HAGCN is tested using the benchmark datasets [STL-10](https://cs.stanford.edu/~acoates/stl10/), [Stanford Cars](https://ai.stanford.edu/~jkrause/cars/car_dataset.html), and [Tiny ImageNet](https://www.kaggle.com/c/tiny-imagenet). 

The STL-10 dataset is a computer vision benchmark with 10 classes of images of size 96 √ó 96, which is widely used for tasks such as representation learning, deep hashing, and self-supervised learning.
Each image has a resolution of 96√ó96. 

The Stanford Car dataset contains over 16,000 images across 196 classes, based on car manufacturer and model year. 
The images are of varying resolutions, but most are high-resolution, typically around 300√ó300 to 600√ó600 pixels. All images were resized to 224√ó224. This dataset shows the visual differences in car model designs over time and is used to evaluate models for fine-grained recognition and transfer learning in computer vision. 

The Tiny ImageNet dataset consists of 200 classes and 500 training images per class, and the ImageNet images are downsampled to 64√ó64. This dataset helps evaluate the scalability and robustness of the model for different object types.

The downloaded images must be embedded into 1-dimensional vectors of size 784 using the [ViT B/16](https://docs.pytorch.org/vision/main/models/generated/torchvision.models.vit_b_16.html) model.
For faster experimentation, Please download the pre-embedded image dataset for the experiment:  you can download the pre-embedded [Stanford_Cars dataset](https://drive.google.com/file/d/1s39IUmYMnvvwMu1eotckh3HF6Mr1QvUt/view?usp=drive_link).

## Code Information

This code loads .npy files organized in folders into a custom PyTorch Dataset and splits them into train, test, and query sets.
It sets up a data loading pipeline for training and evaluating image retrieval or hashing models.

### Data loading
```python
class NpyFolderDataset(Dataset):
    def __init__(self, ...)
    ...
    def __len__(self):
    ...
    def __getitem__(self):
    ...
```

* NpyFolderDataset Class
  
A custom PyTorch Dataset class for loading .npy files organized in a folder structure.
It traverses class-specific directories, collecting file paths and corresponding labels.

* __len__ Method
* 
Returns the total number of samples in the dataset.
This corresponds to the length of the self.data list.

* __getitem__ Method
  
Loads the .npy file at the specified index, converts it into a float tensor, and returns it with its label.
The sample tensor is squeezed to remove extra dimensions.

```python
def get_data_loader():
    ...
    train_test_split()
    ...
    DataLoader()
```

üîÑ get_data_loader Function
Randomly splits the dataset into training, test (database), and query sets.
Returns PyTorch DataLoader objects for each split for efficient batching and loading.

### 2. Model.py

This source file contains the direct implementation of the HAGCN model.
First, the sigmoid function used for binarizing the hash codes is defined as follows.

```python 
class Asig(nn.Module):
    def forward(self, x, alpha):
        return torch.sigmoid(alpha*x)
```

The following is a description of each function in the proposed HAGCN model.

```python
class Machine(nn.Module):
        ...
    def __init__(self)
        ...
    def adj_generator(self, A, device)
        ...
    def fourier(self, L, k=1)
        ...
    def bspline_basis(self, K, x, degree)
        ...
    def chebyshev_polynomials(self, L_hat, K)
        ...
    def lanczos_algorithm(self, A, k, v0=None)
        ...
    def calc_sim(self, x)
        ...
    def forward(self, x, alpha)
```

üîß __init__
Initializes the model structure and hyperparameters, setting different graph filtering weights depending on the task.
Defines the necessary layers, activation functions, and normalization components.

üîó adj_generator
Generates a normalized adjacency matrix and diagonal matrix from the input similarity matrix.
Performs basic preprocessing for graph filtering.

üéº fourier
Computes the eigenvalues and eigenvectors of the graph Laplacian matrix.
Used in Fourier-based graph filtering.

üìê bspline_basis
Generates B-spline basis functions for use in spline filtering.
Implements the recursive Cox-De Boor algorithm.

üßÆ chebyshev_polynomials
Computes Chebyshev polynomials to create bases for filtering.
Efficiently handles repeated linear operations on the graph.

üßæ lanczos_algorithm
Uses the Lanczos algorithm to approximate a symmetric matrix with a tridiagonal matrix and orthogonal basis.
Provides the foundation for Lanczos-based filtering.

üìä calc_sim
Calculates pairwise similarity between feature vectors to produce a similarity matrix.
Provides relationship information for subsequent graph operations.

üöÄ forward
Defines the full forward pass of the model, performing task-specific graph filtering.
Outputs the hash code, similarity matrix, and feature representation.

### 3. engine.py

The following is a description of training steps for our experiments

```python
def run_experiment(k, num_epochs, task, exp_hash_len, train_loader, test_loader, query_loader, device)"
    ...
    for hash_len in exp_hash_len:
        for key in task:
            ...
            machine = Machine( ...)
            criterion = nn.MSELoss()  # Mean Squared Error Loss
            optimizer = optim.Adam(machine.parameters(), lr=0.0001)
            ...
            for idx, epoch in enumerate(range(num_epochs)):
                ...
            with torch.no_grad():
                ...
                for x_batch, y_batch in test_loader:
                    ...
                np.where(dataset_hcodes>=0.5, 1, 0)
                ...
                for x_batch, y_batch in query_loader:
                ...
                testset_hcodes = np.where(testset_hcodes>=0.5, 1, 0)
            mAP = CalcTopMap(...)
```

1Ô∏è‚É£ Model and Experiment Setup
The Machine model is initialized with different combinations of task and hash length.
Defines the loss function (MSE) and optimizer (Adam).

2Ô∏è‚É£ Training Loop
Iterates over training data, calculating reconstruction loss and similarity-based hash loss.
Performs backpropagation to update model parameters.

3Ô∏è‚É£ Hash Code Binarization
Converts sigmoid outputs into binary hash codes using a 0.5 threshold.
The binary values are then scaled to {-1, 1} for evaluation.

4Ô∏è‚É£ Test Set Hash Code Generation
Generates hash codes for the gallery (database) using the test_loader.
Appends each batch's hash codes and labels to lists, then concatenates them.

5Ô∏è‚É£ Query Set Hash Code Generation
Generates hash codes for the query set using the query_loader.
Similarly binarizes and stores hash codes and labels as full arrays.

6Ô∏è‚É£ Retrieval Performance Evaluation (mAP Calculation)
Computes mAP using CalcTopMap() between query and gallery hash codes.
Measures retrieval accuracy based on top-k Hamming distance.

7Ô∏è‚É£ Result Logging and Output
Tracks the best mAP and logs the results to a CSV file.
Prints a summary of the experiment including task, k, and hash_len.

## Usage Instructions & Requrements
Please follow the instructions below to set up the experimental environment.
To train the model, you need to set up the experimental environment. Use a virtual environment such as Anaconda to install the packages listed in the provided requirements.txt file. While various versions of Python modules may be used, the versions specified in the text file reflect the environment used in the experiments.

### 1. Clone the repository

```{shell}
git clone https://github.com/IDASooinKim/DeepHashing.git
```

### 2. Creating conda envs

```{shell}
conda create -n deephashing python=3.8
conda activate deephashing
```

### 3. Install requirements 

```{shell}
pip install -r requirements.txt
```

### 4. Training Data preparation

Each folder in the downloaded dataset represents a class, and each folder contains approximately 50 embeddings of the same class. If you wish to train with custom data, please follow the folder directory structure below.

```
project/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ 0
|   |‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 0.npy
|   |‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 1.npy
‚îÇ   ‚îî‚îÄ‚îÄ 1
```

### 5. Model Train

Model training can be easily run using the command __python main.py__.
If you wish to adjust the batch size, number of epochs, or other parameters, please use the following command:

```{shell}
python main.py --num_epochs 200 --batch_size 64 --num_cls 10 
```

For detailed arguments, please refer to the arguments.py file.
